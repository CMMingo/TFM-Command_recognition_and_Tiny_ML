{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2fbc0f",
   "metadata": {},
   "source": [
    "# Tratamiento de datos: transfer learning\n",
    "\n",
    "En este notebook se detallan todos los pasos seguidos para estandarizar y analizar un conjunto de datos cualquiera, relacionado con detección de palabras de activación. Se encarga de hacer padding sobre los audios cortos (hasta que duren 1 segundo) o de seleccionar la mejor ventana de audio en audios largos, utilizando el RMS. \n",
    "\n",
    "Por razones de privacidad no puedo compartir el conjunto de datos recopilado para el trabajo, pero cualquier persona puede hacer su propia recopilación y subirla en su carpeta data/raw/transfer_learning, de modo que los diferentes audios estén en carpetas separadas dependiendo de la etiqueta que tengan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892089fd",
   "metadata": {},
   "source": [
    "Importamos los paquetes que se van a ir utilizando de forma general a lo largo del código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7e7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(1997)\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Graphics and plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import plotly.express as px\n",
    "\n",
    "# Audio specifics\n",
    "import IPython\n",
    "import wave\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108a4af",
   "metadata": {},
   "source": [
    "Definimos las variables globales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64fe71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables - Paths\n",
    "RAW_PATH = \"./data/raw\"\n",
    "RAW_TL_PATH = os.path.join(RAW_PATH, \"transfer_learning\").replace(\"\\\\\",\"/\")\n",
    "\n",
    "MODIFIED_PATH = \"./data/modified\"\n",
    "MODIFIED_TL_PATH = os.path.join(MODIFIED_PATH, \"standarised_transfer_learning\").replace(\"\\\\\",\"/\")\n",
    "\n",
    "JSON_PATH = \"./data/json\"\n",
    "\n",
    "# Global variables - Others\n",
    "COMMON_NFRAMES = 16000\n",
    "COMMON_NFRAMES_LIBROSA = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adeec9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RAW_TL_PATH):\n",
    "    os.makedirs(RAW_TL_PATH)\n",
    "\n",
    "if not os.path.exists(MODIFIED_TL_PATH):\n",
    "    os.makedirs(MODIFIED_TL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc2e37c",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175829de",
   "metadata": {},
   "source": [
    "# Datos para transfer learning\n",
    "\n",
    "## Descripción de los datos\n",
    "\n",
    "Una de las ventajas del transfer learning es que como el modelo base ya está entrenado, el conjunto de datos que se requiere es mucho más reducido. En nuestro caso hemos conseguido obtener audios de 102 personas diferentes. Cada persona enviaba un audio breve (de entre 1 y 3 segundos) diciendo las palabras sobre las que queremos reentrenar el modelo. En este caso hemos escogido las 18 palabras en español equivalentes al conjunto en inglés que hemos usado en el entrenamiento anterior. De este modo, el objetivo de esta parte del trabajo es investigar si el transfer learning es válido para un pequeño conjunto de comandos de activación, traduciéndolos de un lenguaje a otro.\n",
    "\n",
    "Como hemos comentado, no es necesario un conjunto muy extenso de datos, por lo que no vamos a aplicar ninguna ténica de data augmentation o similar. Tampoco vamos a realizar un análisis exhaustivo de los datos, porque sabemos que todos los audios son válidos ya que se han ido comprobando de manera individual en el momento de la recolección. Es cierto que no son del todo homogéneos, ya que algunos presentan cierto ruido de fondo y algunas de las traducciones se convierten en palabras un poco más largas (más de 2 sílabas), lo que provoca que se tengan pronunciaciones y estiramientos de las palabras diferentes. Sin embargo, consideramos que esto otorga cierta riqueza al conjunto de datos.\n",
    "\n",
    "Por último, comentar que los audios se han obtenido en su mayoría de personas entre los 18 y los 30 años (aunque hay un porcentaje de personas mayores de 30 años) y con una distribución más o menos del 50% entre audios obtenidos de hombres y mujeres. No se han obtenido audios ni de niños ni de personas mayores de 70 años.\n",
    "\n",
    "*Puede ser interesante una rama del trabajo más centrada en el transfer learning para personas con peores capacidades de pronunciación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c5de5",
   "metadata": {},
   "source": [
    "## Estandarización de los audios brutos\n",
    "\n",
    "El único problema con los datos brutos obtenidos es que la duración es muy irregular y la distribución de información en los audios no es homogénea. Los audios se han obtenido por WhatsApp, que no permite enviar audios de menos de 1 segundo, y todos ellos están en formato .ogg. En nuestro caso necesitamos audios exactos de 1 segundo y en formato .wav, así que es necesario estandarizar este conjunto de datos previamente, ya que si no el proceso de transfer learning puede devolver malos resultados.\n",
    "\n",
    "El proceso que se ha seguido para la estandarización es el siguiente:\n",
    "\n",
    "* asegurarse de la creación de las carpetas de salida\n",
    "* lectura del archivo .ogg, fijando el sample rate al valor que queremos\n",
    "* de manera individual se estandariza la duración de los audios:\n",
    "    * en caso de que haya audios de menos de 1 segundo de duración, se ha programado una función que hace padding sobre ellos con silencio, de modo que duren finalmente 1 segundo. Esto no supone ningun problema ya que no es posible perder información importante\n",
    "    * para los audios más largos de 1 segundo se ha procedido con más cuidado ya que hay riesgo de perder información. Recolectando los audios se identificaban diferentes perfiles en las grabaciones: había gente que grababa el comando y dejaba silencio al final, otros empezaban en silencio y el comando se decía justo al final, y otros decían el comando más o menos por el medio, dejando huecos de silencio al principio y al final. Esto suponía un problema ya que no se podían recortar los audios de una manera homogénea para todos los casos. Por ello, lo que se ha hecho es programar una función que se encarga de extraer el segundo con mayor información, utilizando ventanas de 1 segundo de duración y recopilando en cada caso cuál el RMS de dicha ventana. Interando sobre diferentes ventanas a lo largo de la duración del audio, nos quedamos finalmente con aquella que presenta un mayor RMS, suponiendo como hipótesis que ello indica dónde está el comando, ya que todos los audios no tenían un excesivo ruido de fondo como para influir tan significativamente en este proceso\n",
    "* guardar el audio final de 1 segundo de duración en formato .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19fba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas = [\"00-cero\", \"01-uno\", \"02-dos\", \"03-tres\", \"04-cuatro\", \"05-cinco\", \"06-seis\", \"07-siete\", \"08-ocho\", \"09-nueve\", \"10-aceptar\", \"11-rechazar\", \"12-arriba\", \"13-abajo\", \"14-izquierda\", \"15-derecha\", \"16-si\", \"17-no\"]\n",
    "\n",
    "for etiqueta in etiquetas:\n",
    "    if not os.path.exists(os.path.join(MODIFIED_TL_PATH, etiqueta).replace(\"\\\\\", \"/\")):\n",
    "        os.makedirs(os.path.join(MODIFIED_TL_PATH, etiqueta).replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35344b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_short_audio(filename, etiqueta, number):\n",
    "    pad_ms = 1000\n",
    "\n",
    "    signal = AudioSegment.from_ogg(filename)\n",
    "    assert pad_ms > len(signal), \"Audio was longer that 1 second. Path: \" + str(filename)\n",
    "    \n",
    "    silence = AudioSegment.silent(duration=pad_ms-len(signal)+1)\n",
    "    padded = signal + silence  # adding silence after the signal\n",
    "    out_filename = os.path.join(MODIFIED_TL_PATH, etiqueta, str(number)+\".wav\")\n",
    "    padded.export(out_filename, format=\"wav\")\n",
    "    \n",
    "    signal, sample_rate = librosa.load(out_filename, sr=COMMON_NFRAMES_LIBROSA)\n",
    "    signal = signal[:COMMON_NFRAMES_LIBROSA]\n",
    "    sf.write(out_filename, signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6219d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_loudest_second(signal, sample_rate, filename, etiqueta, number):\n",
    "    results = {\n",
    "        \"slices\": [],\n",
    "        \"rms\": []\n",
    "    }\n",
    "\n",
    "    for slice_down in range(0, len(signal)-COMMON_NFRAMES_LIBROSA, int(COMMON_NFRAMES_LIBROSA/15)): # steps of 1470 frames\n",
    "        slice_up = slice_down + COMMON_NFRAMES_LIBROSA if slice_down + COMMON_NFRAMES_LIBROSA < len(signal) else len(signal) \n",
    "        results[\"slices\"].append([slice_down, slice_up])\n",
    "        results[\"rms\"].append(np.sum(librosa.feature.rms(signal[slice_down:slice_up])))\n",
    "    slice_down, slice_up = results[\"slices\"][np.argmax(results[\"rms\"])]\n",
    "\n",
    "    out_filename = os.path.join(MODIFIED_TL_PATH, etiqueta, str(number)+\".wav\")\n",
    "    signal = signal[slice_down:slice_up]\n",
    "    sf.write(out_filename, signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570a08ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-cero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]c:\\Users\\Carlos\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "100%|██████████| 102/102 [07:03<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-uno\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:53<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-dos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [07:00<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-tres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:53<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-cuatro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:59<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05-cinco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [07:00<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-seis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:47<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-siete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [07:08<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-ocho\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:46<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09-nueve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [07:09<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-aceptar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [07:10<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-rechazar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [07:06<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-arriba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [07:37<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-abajo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:50<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-izquierda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:35<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15-derecha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:58<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16-si\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:39<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17-no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [06:41<00:00,  3.94s/it]\n"
     ]
    }
   ],
   "source": [
    "for j, etiqueta in enumerate(etiquetas):\n",
    "    print(etiqueta)\n",
    "\n",
    "    for i, file in enumerate(tqdm(os.listdir(os.path.join(RAW_TL_PATH, etiqueta).replace(\"\\\\\", \"/\")))):\n",
    "        if file.endswith(\".ogg\"):\n",
    "            filename = os.path.join(RAW_TL_PATH, etiqueta, file).replace(\"\\\\\", \"/\")\n",
    "            signal, sample_rate = librosa.load(filename, sr=COMMON_NFRAMES_LIBROSA)\n",
    "\n",
    "            if len(signal) < COMMON_NFRAMES_LIBROSA:\n",
    "                pad_short_audio(filename, etiqueta, i)\n",
    "            else:\n",
    "                extract_loudest_second(signal, sample_rate, filename, etiqueta, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b0914",
   "metadata": {},
   "source": [
    "Una vez terminado el proceso, se ha verificado de manera general que el procedimiento de extracción de la ventana de 1 segundo con mayor información es correcto. Lo único que se ha detectado es que hay algunos casos (muy reducidos en número) en los que el comando en sí no cabía en la ventana de un segundo y por ello ha quedado ligeramente recortado. Sin embargo esto no supone ningún problema, ya que el comando se sigue entendiendo perfectamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f9cc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith wave.open(\"./data/modified/standarised_transfer_learning/10-aceptar/0.wav\", mode=\"rb\") as wav_object:\\n    print(wav_object.getnchannels())\\n    print(wav_object.getsampwidth())\\n    print(wav_object.getframerate())\\n    print(wav_object.getnframes())\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To test some examples\n",
    "\"\"\"\n",
    "with wave.open(\"./data/modified/standarised_transfer_learning/10-aceptar/0.wav\", mode=\"rb\") as wav_object:\n",
    "    print(wav_object.getnchannels())\n",
    "    print(wav_object.getsampwidth())\n",
    "    print(wav_object.getframerate())\n",
    "    print(wav_object.getnframes())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcc255",
   "metadata": {},
   "source": [
    "Verificamos que los nuevos audios tienen las mismas características que el conjunto de datos que hemos utilizado sobre los modelos de speech recognition, refiriéndonos al número de canales, framerate, sample width y número de frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a791377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\00-cero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 165.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\01-uno\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 175.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\02-dos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 177.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\03-tres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 184.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\04-cuatro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 179.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\05-cinco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 179.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\06-seis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 185.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\07-siete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 176.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\08-ocho\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 174.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\09-nueve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 170.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\10-aceptar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 168.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\11-rechazar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 165.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\12-arriba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 184.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\13-abajo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 174.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\14-izquierda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 170.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\15-derecha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 176.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\16-si\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 180.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/modified/standarised_transfer_learning\\17-no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 178.95it/s]\n"
     ]
    }
   ],
   "source": [
    "data_TL = {\n",
    "    \"n_channels\": [],\n",
    "    \"sample_width\": [],\n",
    "    \"framerate\": [],\n",
    "    \"n_frames\": [],\n",
    "    \"files\": [],\n",
    "    \"labels\": []\n",
    "}\n",
    "\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(MODIFIED_TL_PATH)):\n",
    "\n",
    "    if dirpath != MODIFIED_TL_PATH: # ensure we're at sub-folder level; if not, there are no audio files\n",
    "        print(dirpath)\n",
    "        for file in tqdm(filenames):\n",
    "            file_full = os.path.join(dirpath, file).replace(\"\\\\\",\"/\")\n",
    "            with wave.open(file_full, mode=\"rb\") as wav_object:\n",
    "                data_TL[\"n_channels\"].append(wav_object.getnchannels())\n",
    "                data_TL[\"sample_width\"].append(wav_object.getsampwidth())\n",
    "                data_TL[\"framerate\"].append(wav_object.getframerate())\n",
    "                data_TL[\"n_frames\"].append(wav_object.getnframes())\n",
    "                data_TL[\"files\"].append(file_full)\n",
    "                data_TL[\"labels\"].append(dirpath.split(\"\\\\\")[-1])\n",
    "                \n",
    "with open(os.path.join(JSON_PATH, \"basic_wav_info_TL.json\"), \"w\") as json_file:\n",
    "    json.dump(data_TL, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "becfd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_wavs_TL = {\n",
    "    \"n_channels\": {\n",
    "        \"n_channels\": [],\n",
    "        \"files\": []\n",
    "    },\n",
    "    \"sample_width\": {\n",
    "        \"sample_width\": [],\n",
    "        \"files\": []\n",
    "    },\n",
    "    \"framerate\": {\n",
    "        \"framerate\": [],\n",
    "        \"files\": []\n",
    "    },\n",
    "    \"n_frames\": {\n",
    "        \"n_frames\": [],\n",
    "        \"files\": []\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f2c6dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of channels\n",
    "EXPECTED_n_channels = 1\n",
    "\n",
    "for i, channel in enumerate(data_TL[\"n_channels\"]):\n",
    "    if channel != EXPECTED_n_channels:\n",
    "        bad_wavs_TL[\"n_channels\"][\"n_channels\"].append(channel)\n",
    "        bad_wavs_TL[\"n_channels\"][\"files\"].append(data_TL[\"files\"][i])\n",
    "\n",
    "print(len(bad_wavs_TL[\"n_channels\"][\"n_channels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0ad3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Sample width\n",
    "EXPECTED_sample_width = 2\n",
    "\n",
    "for i, sample_width in enumerate(data_TL[\"sample_width\"]):\n",
    "    if sample_width != EXPECTED_sample_width:\n",
    "        bad_wavs_TL[\"sample_width\"][\"sample_width\"].append(sample_width)\n",
    "        bad_wavs_TL[\"sample_width\"][\"files\"].append(data_TL[\"files\"][i])\n",
    "\n",
    "print(len(bad_wavs_TL[\"sample_width\"][\"sample_width\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f339f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Framerate\n",
    "EXPECTED_framerate = COMMON_NFRAMES_LIBROSA\n",
    "\n",
    "for i, framerate in enumerate(data_TL[\"framerate\"]):\n",
    "    if framerate != EXPECTED_framerate:\n",
    "        bad_wavs_TL[\"framerate\"][\"framerate\"].append(framerate)\n",
    "        bad_wavs_TL[\"framerate\"][\"files\"].append(data_TL[\"files\"][i])\n",
    "\n",
    "print(len(bad_wavs_TL[\"framerate\"][\"framerate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26036830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of frames\n",
    "EXPECTED_nframes = COMMON_NFRAMES_LIBROSA\n",
    "\n",
    "for i, frames in enumerate(data_TL[\"n_frames\"]):\n",
    "    if frames != EXPECTED_nframes:\n",
    "        bad_wavs_TL[\"n_frames\"][\"n_frames\"].append(frames)\n",
    "        bad_wavs_TL[\"n_frames\"][\"files\"].append(data_TL[\"files\"][i])\n",
    "\n",
    "print(len(bad_wavs_TL[\"n_frames\"][\"n_frames\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb00f8",
   "metadata": {},
   "source": [
    "Por último, una vez tenemos estandarizados todos los audios, mostramos gráficamente un resumen de los datos que disponemos para el transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e943c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Etiqueta=%{x}<br># muestras=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "00-cero",
          "01-uno",
          "02-dos",
          "03-tres",
          "04-cuatro",
          "05-cinco",
          "06-seis",
          "07-siete",
          "08-ocho",
          "09-nueve",
          "10-aceptar",
          "11-rechazar",
          "12-arriba",
          "13-abajo",
          "14-izquierda",
          "15-derecha",
          "16-si",
          "17-no"
         ],
         "xaxis": "x",
         "y": [
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102,
          102
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Número de muestras por etiqueta"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Etiqueta"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "# muestras"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(columns=[\"num_samples\", \"label\"])\n",
    "for etiqueta in etiquetas:\n",
    "    waves = [i for i in os.listdir(os.path.join(MODIFIED_TL_PATH, etiqueta)) if i.endswith(\".wav\")]\n",
    "    data_df = data_df.append({\"num_samples\": len(waves), \"label\": etiqueta}, ignore_index = True)\n",
    "\n",
    "# Plot\n",
    "fig = px.bar(data_df, x=\"label\", y=\"num_samples\", labels={\"label\": \"Etiqueta\", \"num_samples\": \"# muestras\"}, title=\"Número de muestras por etiqueta\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bafa8",
   "metadata": {},
   "source": [
    "Vemos que tenemos 102 audios de diferentes personas para cada una de las 18 etiquetas seleccionadas, de modo que tenemos un conjunto de datos perfectamente balanceado y, a priori, válido para realizar transfer learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "607db476e417971f05b607c2dd14e77ee8262c2c4c20dea422522c60605a222a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
